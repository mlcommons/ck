{
  "alias": "get-ml-model-llama2",
  "automation_alias": "script",
  "automation_uid": "5b4e0237da074764",
  "cache": true,
  "category": "AI/ML models",
  "env": {
    "CM_ML_MODEL_DATASET": "openorca",
    "CM_ML_MODEL_WEIGHT_TRANSFORMATIONS": "no"
  },
  "input_mapping": {
    "checkpoint": "LLAMA2_CHECKPOINT_PATH"
  },
  "new_env_keys": [
    "CM_ML_MODEL_*",
    "LLAMA2_CHECKPOINT_PATH"
  ],
  "prehook_deps": [
    {
      "enable_if_env": {
        "CM_TMP_REQUIRE_DOWNLOAD": [
          "yes"
        ]
      },
      "env": {
      },
      "force_env_keys": [
        "CM_GIT_CHECKOUT_FOLDER"
      ],
      "names": [
        "hf-zoo"
      ],
      "tags": "get,ml-model,huggingface,zoo,_clone-repo"
    }
  ],
  "tags": [
    "get",
    "raw",
    "ml-model",
    "language-processing",
    "llama2",
    "llama2-70b",
    "text-summarization"
  ],
  "uid": "5db97be9f61244c6",
  "variations": {
    "meta-llama/Llama-2-70b-chat-hf": {
      "group": "huggingface-stub",
      "default": true,
      "env": {
        "CM_GIT_CHECKOUT_FOLDER": "Llama-2-70b-chat-hf",
        "CM_MODEL_ZOO_ENV_KEY": "LLAMA2"
      },
      "adr": {
        "hf-zoo": {
          "tags": "_model-stub.meta-llama/Llama-2-70b-chat-hf"
        }
      }
    },
    "meta-llama/Llama-2-7b-chat-hf": {
      "group": "huggingface-stub",
      "env": {
        "CM_GIT_CHECKOUT_FOLDER": "Llama-2-7b-chat-hf",
        "CM_MODEL_ZOO_ENV_KEY": "LLAMA2"
      },
      "adr": {
        "hf-zoo": {
          "tags": "_model-stub.meta-llama/Llama-2-7b-chat-hf"
        }
      }
    },
    "stub.#": {
      "group": "huggingface-stub",
      "env": {
        "CM_MODEL_ZOO_ENV_KEY": "LLAMA2"
      },
      "adr": {
        "hf-zoo": {
          "tags": "_model-stub.#"
        }
      }
    },
    "batch_size.#": {
      "env": {
        "CM_ML_MODEL_BATCH_SIZE": "#"
      }
    },
    "fp32": {
      "default": true,
      "env": {
        "CM_ML_MODEL_INPUT_DATA_TYPES": "fp32",
        "CM_ML_MODEL_PRECISION": "fp32",
        "CM_ML_MODEL_WEIGHT_DATA_TYPES": "fp32"
      },
      "group": "precision"
    },
    "int8": {
      "env": {
        "CM_ML_MODEL_INPUT_DATA_TYPES": "int8",
        "CM_ML_MODEL_PRECISION": "int8",
        "CM_ML_MODEL_WEIGHT_DATA_TYPES": "int8"
      },
      "group": "precision"
    },
    "pytorch": {
      "default": true,
      "env": {
        "CM_ML_MODEL_FRAMEWORK": "pytorch"
      },
      "group": "framework"
    },
    "pytorch,fp32": {
      "env": {}
    },
    "uint8": {
      "env": {
        "CM_ML_MODEL_INPUT_DATA_TYPES": "uint8",
        "CM_ML_MODEL_PRECISION": "uint8",
        "CM_ML_MODEL_WEIGHT_DATA_TYPES": "uint8"
      },
      "group": "precision"
    }
  },
  "print_env_at_the_end" : {
    "LLAMA2_CHECKPOINT_PATH": "LLAMA2 checkpoint path"
  }
}
