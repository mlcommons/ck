
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../img/logo_v2.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Common automation scripts - Collective Knowledge (CK) and Collective Mind (CM/MLCFlow/CMX automations)</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="green">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cmx-automations" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Collective Knowledge (CK) and Collective Mind (CM/MLCFlow/CMX automations)" class="md-header__button md-logo" aria-label="Collective Knowledge (CK) and Collective Mind (CM/MLCFlow/CMX automations)" data-md-component="logo">
      
  <img src="../../img/logo_v2.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Collective Knowledge (CK) and Collective Mind (CM/MLCFlow/CMX automations)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Common automation scripts
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/mlcommons/ck" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  HOME

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  CMX/CM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../mlperf-inference/" class="md-tabs__link">
          
  
  
    
  
  MLPerf automations

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="https://access.cKnowledge.org" class="md-tabs__link">
        
  
  
    
  
  CK Playground

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="https://github.com/mlcommons/ck/releases" class="md-tabs__link">
        
  
  
    
  
  Releases

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Collective Knowledge (CK) and Collective Mind (CM/MLCFlow/CMX automations)" class="md-nav__button md-logo" aria-label="Collective Knowledge (CK) and Collective Mind (CM/MLCFlow/CMX automations)" data-md-component="logo">
      
  <img src="../../img/logo_v2.svg" alt="logo">

    </a>
    Collective Knowledge (CK) and Collective Mind (CM/MLCFlow/CMX automations)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mlcommons/ck" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    HOME
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    CMX/CM
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            CMX/CM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../install/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../understanding-cmx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Understanding CMX
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../common-automation-actions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CMX commands to share and reuse artifacts with common metadata
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../specific-automation-actions.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CMX automation actions for related artifacts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cm4mlops.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reusing CMX automations and artifacts for MLOps, DevOps and MLPerf
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../create.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Creating new artifacts and automations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../improving-cmx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Improving CMX framework
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../motivation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Motivation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../mlperf-inference/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    MLPerf automations
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            MLPerf automations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v4.1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MLPerf inference benchmark v4.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../mlperf-inference/v5.0/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    MLPerf inference benchmark v5.0
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            MLPerf inference benchmark v5.0
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_3_2" id="__nav_3_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Image Classification
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_2">
            <span class="md-nav__icon md-icon"></span>
            Image Classification
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/image_classification/resnet50/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ResNet50
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3_3" id="__nav_3_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Text to Image
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_3">
            <span class="md-nav__icon md-icon"></span>
            Text to Image
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_3_3_1" id="__nav_3_3_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Stable Diffusion
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_3_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_3_1">
            <span class="md-nav__icon md-icon"></span>
            Stable Diffusion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/text_to_image/sdxl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Run Commands
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_3_3_1_2" id="__nav_3_3_3_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Reproducibility
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_3_3_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            Reproducibility
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/text_to_image/reproducibility/scc24/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    SCC24
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_3_4" id="__nav_3_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    2D Object Detection
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_4">
            <span class="md-nav__icon md-icon"></span>
            2D Object Detection
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/object_detection/retinanet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RetinaNet
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_3_5" id="__nav_3_3_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Automotive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_5">
            <span class="md-nav__icon md-icon"></span>
            Automotive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_5_1" >
        
          
          <label class="md-nav__link" for="__nav_3_3_5_1" id="__nav_3_3_5_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    3D Object Detection
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_3_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_5_1">
            <span class="md-nav__icon md-icon"></span>
            3D Object Detection
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/automotive/3d_object_detection/pointpainting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    PointPainting
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_6" >
        
          
          <label class="md-nav__link" for="__nav_3_3_6" id="__nav_3_3_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Medical Imaging
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_6">
            <span class="md-nav__icon md-icon"></span>
            Medical Imaging
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/medical_imaging/3d-unet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3d-unet
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_3_7" id="__nav_3_3_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Language Processing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_7">
            <span class="md-nav__icon md-icon"></span>
            Language Processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_7_1" >
        
          
          <label class="md-nav__link" for="__nav_3_3_7_1" id="__nav_3_3_7_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Bert-Large
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_3_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_7_1">
            <span class="md-nav__icon md-icon"></span>
            Bert-Large
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/language/bert/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Run Commands
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_7_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_3_7_1_2" id="__nav_3_3_7_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Reproducibility
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_3_3_7_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_7_1_2">
            <span class="md-nav__icon md-icon"></span>
            Reproducibility
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/language/reproducibility/indyscc24-bert/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    IndySCC24
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/language/gpt-j/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GPT-J
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/language/llama2-70b/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLAMA2-70B
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/language/llama3_1-405b/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLAMA3-405B
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/language/mixtral-8x7b/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MIXTRAL-8x7B
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_8" >
        
          
          <label class="md-nav__link" for="__nav_3_3_8" id="__nav_3_3_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Recommendation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_8">
            <span class="md-nav__icon md-icon"></span>
            Recommendation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/recommendation/dlrm-v2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DLRM-v2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3_9" >
        
          
          <label class="md-nav__link" for="__nav_3_3_9" id="__nav_3_3_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Graph Neural Networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_9">
            <span class="md-nav__icon md-icon"></span>
            Graph Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlperf-inference/v5.0/benchmarks/graph/rgat/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    R-GAT
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://access.cKnowledge.org" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CK Playground
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/mlcommons/ck/releases" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Releases
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#why-cm" class="md-nav__link">
    <span class="md-ellipsis">
      Why CM?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cm-automation-recipe-for-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      CM automation recipe for image classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-cm-scripts-works" class="md-nav__link">
    <span class="md-ellipsis">
      How CM scripts works?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-cm-runs-automation-recipes" class="md-nav__link">
    <span class="md-ellipsis">
      How CM runs automation recipes?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-cm-unifies-inputs-outputs-and-environment-variables" class="md-nav__link">
    <span class="md-ellipsis">
      How CM unifies inputs, outputs and environment variables?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-cm-chains-automation-recipes-into-portable-workflows" class="md-nav__link">
    <span class="md-ellipsis">
      How CM chains automation recipes into portable workflows?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-add-new-cm-scripts" class="md-nav__link">
    <span class="md-ellipsis">
      How to add new CM scripts?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-customize-cm-scripts-using-variations" class="md-nav__link">
    <span class="md-ellipsis">
      How to customize CM scripts using variations?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-cache-and-reuse-cm-scripts-output" class="md-nav__link">
    <span class="md-ellipsis">
      How to cache and reuse CM scripts' output?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-use-cm-with-python-virtual-environments" class="md-nav__link">
    <span class="md-ellipsis">
      How to use CM with Python virtual environments?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-debug-cm-scripts" class="md-nav__link">
    <span class="md-ellipsis">
      How to debug CM scripts?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-extendimprove-cm-scripts" class="md-nav__link">
    <span class="md-ellipsis">
      How to extend/improve CM scripts?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-use-cm-with-containers" class="md-nav__link">
    <span class="md-ellipsis">
      How to use CM with containers?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-use-cm-gui-to-run-automation-recipes" class="md-nav__link">
    <span class="md-ellipsis">
      How to use CM GUI to run automation recipes?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-run-mlperf-benchmarks-via-cm" class="md-nav__link">
    <span class="md-ellipsis">
      How to run MLPerf benchmarks via CM?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-use-cm-to-reproduce-research-papers" class="md-nav__link">
    <span class="md-ellipsis">
      How to use CM to reproduce research papers?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-use-cm-as-a-common-interface-to-other-projects" class="md-nav__link">
    <span class="md-ellipsis">
      How to use CM as a common interface to other projects?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#where-to-read-about-the-cm-vision-and-history" class="md-nav__link">
    <span class="md-ellipsis">
      Where to read about the CM vision and history?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-get-in-touch-with-the-cm-community" class="md-nav__link">
    <span class="md-ellipsis">
      How to get in touch with the CM community?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<p>[ <a href="../">Back to documentation</a> ]</p>
<h1 id="cmx-automations">CMX automations</h1>
<h2 id="why-cm">Why CM?</h2>
<p>Collective Mind (CM) is a <a href="../CONTRIBUTING.md">community project</a> to develop 
a <a href="https://access.cknowledge.org/playground/?action=scripts">collection of portable, extensible, technology-agnostic and ready-to-use automation recipes
for MLOps and DevOps with a human-friendly interface (aka CM scripts)</a>
that can help to automate all the manual steps required to prepare, build, run, benchmark and optimize complex ML/AI applications 
on any platform with any software and hardware. 
They require Python 3.7+ with minimal dependencies and can run natively on Ubuntu, MacOS, Windows, RHEL, Debian, Amazon Linux
and any other operating system, in a cloud or inside automatically generated containers.</p>
<p>CM scripts were originally developed based on the following requirements from the
<a href="https://github.com/mlcommons/ck/blob/master/docs/taskforce.md">MLCommons engineers and researchers</a> 
to help them automatically build, benchmark and optimize complex MLPerf benchmarks
across diverse and continuously changing models, data sets, software and hardware
from Nvidia, Intel, AMD, Google, Qualcomm, Amazon and other vendors:
* must work out of the box with the default options and without the need to edit some paths, environment variables and configuration files;
* must be non-intrusive, easy to debug and must reuse existing 
  user scripts and automation tools (such as cmake, make, ML workflows, 
  python poetry and containers) rather than substituting them; 
* must have a very simple and human-friendly command line with a Python API and minimal dependencies;
* must require minimal or zero learning curve by using plain Python, native scripts, environment variables 
  and simple JSON/YAML descriptions instead of inventing new workflow languages;
* must have the same interface to run all automations natively, in a cloud or inside containers.</p>
<p>Let's use a relatively simple image classification example to explain how CM achieves that
and how it helps to automate much more complex projects including <a href="mlperf">MLPerf benchmarks</a>
and <a href="https://cTuning.org/ae/micro2023.html">reproducibility initatives</a>
at ML and Systems conferences.</p>
<details closed>
<summary><b>Expand to see the feedback and requirements from MLCommons researchers and engineers</b></summary>


While image classification sounds like a trivial example nowadays, it may still require many manual steps
to download some validation data sets and models, install frameworks and low-level dependencies
and update various environment variables and paths depending on your platform and target hardware 
(for example CPU vs CUDA).

You may also need to make sure that all dependencies are compatible (for example that ONNX run-time 
or PyTorch framework is compatible with your CUDA version, etc).
Of course, you can also develop a container and fix all the versions but what if you or someone else 
want to try a different CUDA version or newer ONNX/TF/PyTorch framework or different operating system
or different model or different data set or different framework or different hardware?

While helping MLCommons automate [MLPerf inference benchmarks](https://github.com/mlcommons/inference) 
and run them across diverse models, data sets, software and hardware, 
we've realized that there is no portable and technology-agnostic automation tool 
that can handle such cases.

The feedback from [MLCommons engineers and researchers](taskforce.md) motivated us
to develop a simple automation framework that can help them 
assemble, run, benchmark and optimize complex AI/ML applications 
across diverse and continuously changing models, data sets, software and hardware
from Nvidia, Intel, AMD, Google, Qualcomm, Amazon and other vendors.

</details>

<h2 id="cm-automation-recipe-for-image-classification">CM automation recipe for image classification</h2>
<p>We designed CM as a <a href="https://github.com/mlcommons/ck/tree/master/cm">small Python library</a> 
with a human-friendly command line, simple Python API and minimal dependencies 
needed to implement automation recipes (Python 3.7+, PIP, pyyaml, git, wget)
and chain them into portable workflows. CM scripts can run natively (development mode) 
or inside containers that CM generates on the fly (stable mode).</p>
<p>Most of the time, these dependencies are already installed on your platform.
In such case, you should be able to prepare and run image classification with ONNX,
ImageNet validation data set and ResNet-50 on Linux, MacOS, Windows and any other
operating system using a few CM commands:</p>
<p><sup></p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>cmind
cm<span class="w"> </span>pull<span class="w"> </span>repo<span class="w"> </span>mlcommons@cm4mlops<span class="w"> </span>--checkout<span class="o">=</span>dev
cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span>
</code></pre></div>
<p></sup></p>
<p><em>Note that you may need to re-login when you install cmind for the first time
 to let your platform pick up path to the <code>cm</code> command line front-end.</em></p>
<p>You can also run and customize above automation recipe in alternative ways as follows:</p>
<p><sup></p>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span><span class="w"> </span>--help

cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;download file _wget&quot;</span><span class="w"> </span>--url<span class="o">=</span>https://cKnowledge.org/ai/data/computer_mouse.jpg<span class="w"> </span>--verify<span class="o">=</span>no<span class="w"> </span>--env.CM_DOWNLOAD_CHECKSUM<span class="o">=</span>45ae5c940233892c2f860efdf0b66e7e
cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span><span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg

cmr<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span><span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg
cmr<span class="w"> </span>--tags<span class="o">=</span>python,app,image-classification,onnx,_cpu<span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg
cmr<span class="w"> </span>3d5e908e472b417e<span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg

cm<span class="w"> </span>docker<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span><span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg

cm<span class="w"> </span>gui<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span>
</code></pre></div>
<p></sup></p>
<p>If you encounter some issues, please check <a href="installation.md">CM installation guide</a> - 
if it doesn't help you, please report your issues <a href="https://github.com/mlcommons/ck/issues">here</a> 
and/or contact us via our <a href="https://discord.gg/JjWNWXKxwT">public Discord server</a> - 
CM is a <a href="../CONTRIBUTING.md">community project</a> being developed 
and improved across diverse software and hardware  based on your feedback! </p>
<h2 id="how-cm-scripts-works">How CM scripts works?</h2>
<p>Next, we briefly explain how CM commands work - it will help you understand
what happens when you see similar commands in MLPerf results, README files, 
technical reports, research papers, Jupyter notebooks, 
Google colab, containers, scripts and artifact appendices.</p>
<p>Whenever you run <code>cm run script "python app image-classification onnx _cpu"</code> 
or <code>cmr "python app image-classification onnx _cpu"</code>, 
the <a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/automation/script/module.py">CM script automation</a> 
will simply search for <code>_cm.yaml</code> and <code>_cm.json</code> files (CM meta-description dictionary) in all <code>script</code> 
directories in all software projects registered in CM via <code>cm pull repo</code>.</p>
<p>In our case, we've pulled <a href="https://github.com/mlcommons/ck">github.com/mlcommons/ck project</a>
that has most MLCommons' CM automation recipes embedded 
in a <a href="https://github.com/mlcommons/ck/tree/master/cm-mlops/script"><code>cm-mlops/script</code> directory</a>. </p>
<p><em>Note that you can pull any public or private Git repository, download any software project
 or register any local directory in the CM to search for embedded automation recipes.</em></p>
<p>CM will then try to match all your tags without <code>_</code> prefix (<code>_</code> in tags mark 
the so-called CM script variations that customize a give script behavior 
and will be described later)  with a <code>tags</code> list in the CM meta-description dictionary.
In our case, it will match the corresponding <a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/script/app-image-classification-onnx-py/_cm.yaml#L9"><code>_cm.yaml</code></a> 
in <code>$HOME/CM/repos/mlcommons@cm4mlops/script/app-image-classification-onnx-py/_cm.yaml</code> - 
a wrapper for a given CM automation recipe.</p>
<p><em>Note that if you use unique ID instead of tags to identify automation (such as <code>3d5e908e472b417e</code>), 
 CM will try to match <code>uid</code> string in the CM meta descriptions instead of tags.</em></p>
<h2 id="how-cm-runs-automation-recipes">How CM runs automation recipes?</h2>
<p>Whenever CM finds a directory with a requested automation recipe, 
it performs the following steps:
* run <code>preprocess</code> function in <code>customize.py</code> if exists
* run <code>run.sh</code> (Linux) or <code>run.bat</code> (Windows) if exists
* run <code>postprocess</code> function in <code>customize.py</code> if exists</p>
<p>Such organization makes it possible to use either Python or native OS scripts or
both to implement CM automation recipes while minimizing the learning curve
for CM understanding, development and debugging as requested by CM users.</p>
<p>Furthermore, CM scripts can keep the source code of
image classification (as shown <a href="https://github.com/mlcommons/ck/tree/master/cm-mlops/script/app-image-classification-onnx-py/src">here</a>)
that we can easily move around
between projects without hardwiring paths and names.</p>
<h2 id="how-cm-unifies-inputs-outputs-and-environment-variables">How CM unifies inputs, outputs and environment variables?</h2>
<p>CM allows you to pass environment variables to <code>customize.py</code>
and native scripts using <code>--env.ENV=VALUE</code>. </p>
<p>When you use some flags such as <code>--input</code> in our image classification
example, it will be also converted into an environment variable
using <a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/script/app-image-classification-onnx-py/_cm.yaml#L78"><code>input_mapping</code> dictionary</a> 
in the CM meta description of this script.</p>
<p>All environment variables are aggregated in <code>env</code> dictionary inside CM
and then passed to <code>preprocess</code> function in <code>customize.py</code> where you can modify
it programmatically. </p>
<p>They are then passed to the <code>run</code> script. Since new environment variables
are not preserved after <code>run</code> script, one can pass new environment variables
back to CM using <code>tmp-run-env.out</code> with ENV=KEY strings as shown <a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/script/app-image-classification-onnx-py/run.sh#L37">here</a>
or using <code>tmp-run-state.json</code> as shown <a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/script/app-image-classification-onnx-py/src/onnx_classify.py#L171">here</a>.</p>
<h2 id="how-cm-chains-automation-recipes-into-portable-workflows">How CM chains automation recipes into portable workflows?</h2>
<p>CM scripts provide a technology-agnostic wrapper with simple tags, CLI and Python API to prepare and run 
user code snippets and native scripts/tools while unifying their inputs and outputs, paths and environment variables.</p>
<p>Such architecture makes it possible to easily chain existing user scripts and tools into portable, technology-agnostic and powerful workflows
instead of substituting or rewriting them.</p>
<p>It is possible to chain CM scripts using simple 
<a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/script/app-image-classification-onnx-py/_cm.yaml#L23"><code>deps</code> list</a> 
in a meta description of a given script:</p>
<p><sup></p>
<div class="highlight"><pre><span></span><code><span class="nt">deps</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">detect,os</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,sys-utils-cm</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">names</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python3</span>
<span class="w">  </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,python3</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,cuda</span>
<span class="w">  </span><span class="nt">names</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cuda</span>
<span class="w">  </span><span class="nt">enable_if_env</span><span class="p">:</span>
<span class="w">    </span><span class="nt">USE_CUDA</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">yes</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,cudnn</span>
<span class="w">  </span><span class="nt">names</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cudnn</span>
<span class="w">  </span><span class="nt">enable_if_env</span><span class="p">:</span>
<span class="w">    </span><span class="nt">USE_CUDA</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">yes</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,dataset,imagenet,image-classification,original</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,dataset-aux,imagenet-aux,image-classification</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,ml-model,resnet50,_onnx,image-classification</span>
<span class="w">  </span><span class="nt">names</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ml-model</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,generic-python-lib,_package.Pillow</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,generic-python-lib,_package.numpy</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,generic-python-lib,_package.opencv-python</span>


<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,generic-python-lib,_onnxruntime</span>
<span class="w">  </span><span class="nt">names</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">onnxruntime</span>
<span class="w">  </span><span class="nt">skip_if_env</span><span class="p">:</span>
<span class="w">    </span><span class="nt">USE_CUDA</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">yes</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">get,generic-python-lib,_onnxruntime_gpu</span>
<span class="w">  </span><span class="nt">names</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">onnxruntime</span>
<span class="w">  </span><span class="nt">enable_if_env</span><span class="p">:</span>
<span class="w">    </span><span class="nt">USE_CUDA</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">yes</span>
</code></pre></div>
<p></sup></p>
<p>Each entry in this list is a dictionary that specifies which CM script to run using <code>tags</code>.
Internally, CM will be updating <code>env</code> dictionary (flat environment) and <code>state</code> dictionary 
(to let scripts exchange complex data structures besides environment variables).</p>
<p>If you run CM via command line, you can see internal <code>env</code> and <code>state</code> dictionaries by adding <code>-j</code> flag:</p>
<div class="highlight"><pre><span></span><code>cmr<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span><span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg<span class="w"> </span>-j
</code></pre></div>
<p><em>Note that we use similar approach for updating environment variables similar 
 to calling native scripts - by default, they do not alter environment
 variables at the host. However, CM allows you to do that 
 by explicitly specifying which environment variables and state keys
 will be updated at the host using <code>new_env_keys</code> and <code>new_state_keys</code>
 in the meta of a given script as shown <a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/script/app-image-classification-onnx-py/_cm.yaml#L88">here</a>.
 This helped us make behavior of complex CM workflows more deterministic
 and reproducible.</em></p>
<p>Each sub-dependency can be turned on or off using environment variables
using <code>enable_if_env</code> dictionary or <code>disable_if_env</code> dictionary.</p>
<p>You can also specify <code>version_min</code>, <code>version_max</code> and <code>version</code> in these
dependencies. You can also give them some specific names such as <code>python</code>
and pass versions and environment variables only to a specific script in a pipeline as follows:
<div class="highlight"><pre><span></span><code>cmr<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span><span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg<span class="w"> </span>--adr.python.version_min<span class="o">=</span><span class="m">3</span>.9
</code></pre></div></p>
<p>This functionality is usually implemented inside ad-hoc bash or shell scripts 
with many hardwired paths and names - CM simply makes such scripts and tools 
portable and reusable while enabling technology-agnostic automation workflows 
with a unified interface that can adapt to any operating system and are easy 
to understand.</p>
<p>We can now assemble complex automation workflows by reusing all portable
scripts from <a href="https://access.cknowledge.org/playground/?action=scripts">the community</a>.</p>
<p>In our example, we reused CM scripts to <a href="https://github.com/mlcommons/ck/tree/master/cm-mlops/script/detect-os">detect OS features</a>, 
install system dependencies on <a href="https://github.com/mlcommons/ck/tree/master/cm-mlops/script/get-sys-utils-cm">any supported OS</a> 
(Ubuntu, MacOS, RHEL, Arch, Debian, SLES, Windows, etc),
detect or install Python and PIP packages, download and preprocess data sets and models, etc.</p>
<h2 id="how-to-add-new-cm-scripts">How to add new CM scripts?</h2>
<p>One of the main requirement for CM was to provide a very light-weight connectors 
between existing automation scripts and tools rather than substituting them.</p>
<p>You can add your own scripts and tools to CM using the following command
that will create a ready-to-use dummy CM script:</p>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>add<span class="w"> </span>script<span class="w"> </span>my-script<span class="w"> </span>--tags<span class="o">=</span>my,script
</code></pre></div>
<p>You can already run this dummy script and plug it into other CM workflows:
<div class="highlight"><pre><span></span><code>cmr<span class="w"> </span><span class="s2">&quot;my script&quot;</span>
</code></pre></div></p>
<p>You can also run it from python as follows:
<div class="highlight"><pre><span></span><code>import<span class="w"> </span>cmind
<span class="nv">output</span><span class="o">=</span>cmind.access<span class="o">({</span><span class="s1">&#39;action&#39;</span>:<span class="s1">&#39;run&#39;</span>,<span class="w"> </span>
<span class="w">                     </span><span class="s1">&#39;automation&#39;</span>:<span class="s1">&#39;script&#39;</span>,<span class="w"> </span>
<span class="w">                     </span><span class="s1">&#39;tags&#39;</span>:<span class="s1">&#39;my,script&#39;</span><span class="o">})</span>
<span class="k">if</span><span class="w"> </span>output<span class="o">[</span><span class="s1">&#39;return&#39;</span><span class="o">]==</span><span class="m">0</span>:<span class="w"> </span>print<span class="w"> </span><span class="o">(</span>output<span class="o">)</span>
</code></pre></div></p>
<h2 id="how-to-customize-cm-scripts-using-variations">How to customize CM scripts using variations?</h2>
<p>Sometimes we need to set multiple environment variables or run a set of extra CM scripts
for a specific purpose (different hardware target or model or dataset).</p>
<p>We introduced special tags with <code>_</code>, called <em>variations</em> or <em>variation tags</em>, 
that allow you to update a set of environment variables and add extra scripts
to the chain of dependencies.</p>
<p>Such variations are defined using <a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/script/app-image-classification-onnx-py/_cm.yaml#L66"><code>variations</code> dictionary</a> 
in the meta description of a given CM script.</p>
<p>For example, our script has 2 variations <code>_cuda</code> and <code>_cpu</code>.</p>
<p>If you want to use CUDA implementation of the image classification example, 
you can add this variation to the tags that will set <code>USE_CUDA</code> environment to <code>yes</code>
and will turn on a specific CM script in <code>deps</code> to install ONNX for CUDA:</p>
<div class="highlight"><pre><span></span><code>cmr<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cuda&quot;</span><span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg
</code></pre></div>
<h2 id="how-to-cache-and-reuse-cm-scripts-output">How to cache and reuse CM scripts' output?</h2>
<p>By default, CM scripts run in the current directory and record all new files there.</p>
<p>For example, the following universal download script will download 
computer mouse image to the current directory:</p>
<p><sup></p>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>run<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;download file _wget&quot;</span><span class="w"> </span>--url<span class="o">=</span>https://cKnowledge.org/ai/data/computer_mouse.jpg<span class="w"> </span>--verify<span class="o">=</span>no<span class="w"> </span>--env.CM_DOWNLOAD_CHECKSUM<span class="o">=</span>45ae5c940233892c2f860efdf0b66e7e
</code></pre></div>
<p></sup></p>
<p>In some cases, we want to cache and reuse the output of automation recipes (such as downloading models, preprocessing data sets or building some applications)
rather than just downloading it to the current directory.</p>
<p>Following the feedback from our users, we implemented a <code>cache</code> automation in CM similar to <code>script</code>.
Whenever CM encounters <code>"cache":true</code> in a meta description of a given script, it will create
a <code>cache</code> directory in <code>$HOME/CM/repos/local</code> with some unique ID and the same tags as <code>script</code>,
and will execute that script there to record all the data in cache. </p>
<p>Whenever the same CM script is executed and CM finds an associated cache entry, 
it will skip execution and will reuse files from that entry.</p>
<p>Furthermore, it is possible to reuse large cached files in other projects that call the same CM scripts!</p>
<p>You can see cache entries and find a specific one as follows:</p>
<div class="highlight"><pre><span></span><code>cmr<span class="w"> </span><span class="s2">&quot;get ml-model resnet50 _onnx&quot;</span><span class="w"> </span>-j

cm<span class="w"> </span>show<span class="w"> </span>cache
cm<span class="w"> </span>show<span class="w"> </span>cache<span class="w"> </span><span class="s2">&quot;get ml-model resnet50 _onnx&quot;</span><span class="w"> </span>
cm<span class="w"> </span>find<span class="w"> </span>cache<span class="w"> </span><span class="s2">&quot;download file ml-model resnet50 _onnx&quot;</span><span class="w"> </span>
cm<span class="w"> </span>info<span class="w"> </span>cache<span class="w"> </span><span class="s2">&quot;download file ml-model resnet50 _onnx&quot;</span><span class="w"> </span>
</code></pre></div>
<p>You can clean some cache entries as follows:
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>rm<span class="w"> </span>cache<span class="w"> </span>--tags<span class="o">=</span>ml-model,resnet50
</code></pre></div></p>
<p>You can also clean all CM <code>cache</code> entries and start from scratch as follows:
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>rm<span class="w"> </span>cache<span class="w"> </span>-f
</code></pre></div></p>
<p>In fact, you can remove <code>$HOME/CM</code> to reset CM framework completely
and remove all downloaded repositories and cached entries.</p>
<h2 id="how-to-use-cm-with-python-virtual-environments">How to use CM with Python virtual environments?</h2>
<p>Using CM <code>cache</code> makes it possible to run CM automations for multiple virtual environments
installed inside CM <code>cache</code> entries. It is possible to run CM automations with different Python
virtual environments transparently to users while avoiding messing up native user environment.</p>
<p>We created the following CM automation recipe to create virtual environments:</p>
<div class="highlight"><pre><span></span><code>cmr<span class="w"> </span><span class="s2">&quot;install python-venv&quot;</span><span class="w"> </span>--name<span class="o">=</span>mlperf
cm<span class="w"> </span>show<span class="w"> </span>cache<span class="w"> </span><span class="s2">&quot;python-venv name-mlperf&quot;</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">CM_SCRIPT_EXTRA_CMD</span><span class="o">=</span><span class="s2">&quot;--adr.python.name=mlperf&quot;</span>
</code></pre></div>
<p>If you now run our image classification automation recipe, 
it will reuse model and dataset from the cache, but will
use the newly created virtual environment <code>mlperf</code> for running the script.</p>
<h2 id="how-to-debug-cm-scripts">How to debug CM scripts?</h2>
<p>One of the requirements from CM users was to avoid new and/or complex ways to debug CM automations.
Using native scripts and Python code makes it possible to apply standard techniques and tools to debug CM automations.</p>
<p>We were also asked to add <code>--debug</code> flag to open a shell after the last native script is executed - 
this allows users to rerun the last command line with all environment variables and paths assembled by CM
while having a full and native access to change environment and run the final command 
(such as pinning threads, changing batch sizes, modifying files, etc).</p>
<p>You can try it as follows on Linux, MacOS, Windows or other operating system as follows:</p>
<div class="highlight"><pre><span></span><code>cmr<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span><span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg<span class="w"> </span>--debug
</code></pre></div>
<p>You can also use GDB via environment variable <code>--env.CM_RUN_PREFIX="gdb --args "</code>
to run the final command via GDB.</p>
<h2 id="how-to-extendimprove-cm-scripts">How to extend/improve CM scripts?</h2>
<p>CM is a <a href="../CONTRIBUTING.md">community project</a> where <a href="https://github.com/mlcommons/ck/tree/master/cm-mlops/script">CM scripts</a> 
are continuously improved to run on different hardware with different software 
while keeping backward compatibility through the unified CM interface, tags and variations.</p>
<p>Whenever you encounter an issue or want to have support for your own project and environment, 
please update these scripts and send a PR to the <a href="https://github.com/mlcommons/ck">CM GitHub</a>.</p>
<p>You can also reach us via <a href="https://discord.gg/JjWNWXKxwT">public Discord server</a> 
if you questions or suggestions.</p>
<h2 id="how-to-use-cm-with-containers">How to use CM with containers?</h2>
<p>One of the key requirements for CM was to run automation natively or inside containers in the same way.</p>
<p>We want CM scripts to adapt to the current/latest environment natively or run in the
container automatically generated on the fly when requested by user for more stability and determinism.</p>
<p>In such case, we can get rid of separate development of native scripts/workflows and Dockerfile 
and use the same CM commands instead.</p>
<p>To run a given script in an automatically-generated container, you can simply substitute <code>cm run script</code> 
with <code>cm docker script</code> or <code>cmr</code> with <code>cmrd</code>:</p>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>docker<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span>
</code></pre></div>
<p>CM will automatically generate a Dockerfile with Ubuntu 22.04 in the <code>dockerfiles</code> 
directory of a given script, will build container with the same CM command
and will run it inside container.</p>
<ul>
<li>If you want to stay in the container, you can add flag <code>--docker_it</code>.</li>
<li>You can change OS inside container using <code>--docker_base_image</code>, <code>--docker_os</code> and <code>--docker_os_version</code>.</li>
</ul>
<p>The tricky part is when we want to use host files and directories with a given CM script inside container. 
To make it easier for users, we have implemented automatic detection and mounting of files and directories 
in CM script.</p>
<p>Developers of a CM script just need to specify which flags and environment variables are local files or directories
using <code>input_paths</code> in <code>docker</code> dictionary of the meta-description of this script:</p>
<div class="highlight"><pre><span></span><code><span class="nt">docker</span><span class="p">:</span>
<span class="w">  </span><span class="nt">skip_run_cmd</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;no&#39;</span>
<span class="w">  </span><span class="nt">all_gpus</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;yes&#39;</span>
<span class="w">  </span><span class="nt">input_paths</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">input</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">env.CM_IMAGE</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output</span>
<span class="w">  </span><span class="nt">skip_input_for_fake_run</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">input</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">env.CM_IMAGE</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">j</span>
<span class="w">  </span><span class="nt">pre_run_cmds</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">echo \&quot;CM pre run commands\&quot;</span>
</code></pre></div>
<p>When you run the same script via container with the local computer_mouse.jpg file as an input,
CM will automatically mount current directory and will update the input to the CM script
inside container with the internal path:</p>
<p><sup></p>
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>docker<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span><span class="w"> </span>--input<span class="o">=</span>computer_mouse.jpg

...

docker<span class="w"> </span>build<span class="w">  </span>-f<span class="w"> </span>D:<span class="se">\W</span>ork1<span class="se">\C</span>M<span class="se">\c</span>k<span class="se">\c</span>m-mlops<span class="se">\s</span>cript<span class="se">\a</span>pp-image-classification-onnx-py<span class="se">\d</span>ockerfiles<span class="se">\u</span>buntu_22.04.Dockerfile<span class="w"> </span><span class="se">\</span>
<span class="w">              </span>-t<span class="w"> </span>cknowledge/cm-script-app-image-classification-onnx-py:ubuntu-22.04-latest<span class="w"> </span>.

...

Container<span class="w"> </span>launch<span class="w"> </span>command:
docker<span class="w"> </span>run<span class="w">  </span>--entrypoint<span class="w"> </span><span class="s2">&quot;&quot;</span><span class="w">  </span>--gpus<span class="o">=</span>all<span class="w"> </span>-v<span class="w"> </span>D:<span class="se">\W</span>ork1<span class="se">\C</span>M<span class="se">\c</span>k<span class="se">\d</span>ocs<span class="se">\c</span>omputer_mouse.jpg:/cm-mount/Work1/CM/ck/docs/computer_mouse.jpg<span class="w"> </span>
<span class="w">                            </span>cknowledge/cm-script-app-image-classification-onnx-py:ubuntu-22.04-latest<span class="w"> </span>
<span class="w">                            </span>bash<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;echo \&quot;CM pre run commands\&quot; &amp;&amp; </span>
<span class="s2">                            cm run script --tags=python,app,image-classification,onnx,_cpu </span>
<span class="s2">                            --input=/cm-mount/Work1/CM/ck/docs/computer_mouse.jpg &quot;</span>

CM<span class="w"> </span>pre<span class="w"> </span>run<span class="w"> </span>commands
</code></pre></div>
<p></sup></p>
<p>It is now possible to download large data sets and models to the host from CM containers
or pass host scratch pads and data to CM containers transparently to a user!</p>
<h2 id="how-to-use-cm-gui-to-run-automation-recipes">How to use CM GUI to run automation recipes?</h2>
<p>Another request from CM/MLCommons users was to have a simple GUI that can generate CM commands with user-friendly selector.</p>
<p>We've implemented a CM script called <a href="https://github.com/mlcommons/ck/tree/master/cm-mlops/script/gui"><code>gui</code></a> 
that provides a universal Streamlit GUI for any CM script. </p>
<p>You just need to describe the inputs for a given script via <a href="https://github.com/mlcommons/ck/blob/master/cm-mlops/script/app-image-classification-onnx-py/_cm.yaml#L91">meta-description</a>
as shown for our image classification example:</p>
<div class="highlight"><pre><span></span><code><span class="nt">input_description</span><span class="p">:</span>
<span class="w">  </span><span class="nt">input</span><span class="p">:</span><span class="w"> </span>
<span class="w">    </span><span class="nt">desc</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Path</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">JPEG</span><span class="nv"> </span><span class="s">image</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">classify&quot;</span>
<span class="w">  </span><span class="nt">output</span><span class="p">:</span><span class="w"> </span>
<span class="w">    </span><span class="nt">desc</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Output</span><span class="nv"> </span><span class="s">directory</span><span class="nv"> </span><span class="s">(optional)&quot;</span>
<span class="w">  </span><span class="nt">j</span><span class="p">:</span>
<span class="w">    </span><span class="nt">desc</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Print</span><span class="nv"> </span><span class="s">JSON</span><span class="nv"> </span><span class="s">output&quot;</span>
<span class="w">    </span><span class="nt">boolean</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</code></pre></div>
<p>You can run this GUI for your CM script as follows:
<div class="highlight"><pre><span></span><code>cm<span class="w"> </span>gui<span class="w"> </span>script<span class="w"> </span><span class="s2">&quot;python app image-classification onnx _cpu&quot;</span>
</code></pre></div></p>
<p>This GUI will allow you to customize your script and run it on your host.</p>
<h2 id="how-to-run-mlperf-benchmarks-via-cm">How to run MLPerf benchmarks via CM?</h2>
<p>CM was originally designed to make it easier to run <a href="https://arxiv.org/abs/1911.02549">MLPerf inference benchmarks</a>.</p>
<p>While MLPerf inference has a common benchmarking engine called <a href="https://github.com/mlcommons/inference/tree/master/loadgen">loadgen</a>,
setting up a given platform, installing all tools, downloading and preprocessing all models and data sets, 
updating paths and environment variables, figuring out default parameters for various scenarios, preparing a loadgen command line,
keeping track of continuous updates in MLPerf rules, running multiple experiments and submitting results
is a major challenge for old and new submitters (see <a href="https://doi.org/10.5281/zenodo.10605079">MLPerf inference v4.0 submitter orientation for automation</a>.</p>
<p>We created several CM scripts to prepare and run different implementations of MLPerf inference (reference, Nvidia, Intel, Qualcomm, Deep Sparse, etc)
with a master CM script to run them all out-of-the-box natively or inside automatically-generated containers 
<a href="https://github.com/mlcommons/ck/tree/master/cm-mlops/script/run-mlperf-inference-app">run-mlperf-inference-app</a>.
CM helped us to implement it as a simple pipeline with a common and human-friendly interface while reusing all existing automation recipes.</p>
<p>This script was successfully validated to <a href="https://github.com/mlcommons/ck/blob/master/docs/mlperf/inference/README.md">modularize MLPerf inference benchmarks</a> 
and help the community automate more than 95% of all performance and power submissions in the v3.1 round
across more than 120 system configurations (models, frameworks, hardware) 
while reducing development and maintenance costs.</p>
<p>Please check this <a href="mlperf/inference">documentation</a> for more details.</p>
<h2 id="how-to-use-cm-to-reproduce-research-papers">How to use CM to reproduce research papers?</h2>
<p>Following the successful validation of CM concept to modularize and run MLPerf inference benchmarks across diverse software and hardware,
the community test it to make it easier to reproduce results from research papers during artifact evaluation and other reproducibility
initiatives at <a href="https://ctuning.org/ae/micro2023.html">systems conferences</a>.</p>
<p>The idea is to provide a common interface to prepare and run experiments from research papers.
See the latest CM scripts to rerun some experiments from the <a href="https://github.com/ctuning/cm4research/tree/main/script">ACM/IEEE MICRO'23 conference</a>
and from the <a href="tutorials/scc23-mlperf-inference-bert.md">Student Cluster Competition at Supercomputing'23</a>.</p>
<h2 id="how-to-use-cm-as-a-common-interface-to-other-projects">How to use CM as a common interface to other projects?</h2>
<p>While CM was successfully validated to unify, modularize and automate MLPerf benchmarks,
it turned out to be applicable to any software project. </p>
<p>The community started using CM as a common and human-friendly interface to run other software projects 
and manage experiments across diverse models, data sets, software and hardware while making them more modular, 
portable and reusable.</p>
<p>Please check <a href="tutorials">other CM tutorials</a>, <a href="../">CM documentation</a> and our <a href="https://www.youtube.com/watch?v=7zpeIVwICa4">ACM REP'23 keynote</a>
for more details.</p>
<h2 id="where-to-read-about-the-cm-vision-and-history">Where to read about the CM vision and history?</h2>
<ul>
<li>ACM REP'23 keynote about MLCommons CM: <a href="https://doi.org/10.5281/zenodo.8105339">slides</a> <a href="https://youtu.be/_1f9i_Bzjmg">YouTube</a></li>
<li>ACM TechTalk'21 about automating research projects: <a href="https://www.youtube.com/watch?v=7zpeIVwICa4">YouTube</a> <a href="https://learning.acm.org/binaries/content/assets/leaning-center/webinar-slides/2021/grigorifursin_techtalk_slides.pdf">slides</a></li>
<li><a href="history.md">Project history</a></li>
</ul>
<h2 id="how-to-get-in-touch-with-the-cm-community">How to get in touch with the CM community?</h2>
<p>This is a community project being developed by the <a href="taskforce.md">MLCommons Task Force on Automation and Reproducibility</a>
based on your feedback and <a href="../CONTRIBUTING.md">contributions</a> - please join our <a href="https://discord.gg/JjWNWXKxwT">public Discord server</a> if you 
would like to help with developments or have questions, suggestions and feature requests.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.tabs.link", "content.code.copy", "navigation.expand", "navigation.sections", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>