# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: MLPerf inference bert (deepsparse, tf, onnxruntime, pytorch)

on:
  pull_request:
    branches: [ "master", "dev" ]
    paths:
      - '.github/workflows/test-mlperf-inference-bert-deepsparse-tf-onnxruntime-pytorch.yml'
      - 'cm-mlops/**'
      - '!cm-mlops/**.md'

jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        # 3.12 didn't work on 20240305 - need to check
        python-version: [ "3.11", "3.9" ]
        backend: [ "deepsparse", "tf", "onnxruntime", "pytorch" ]
        precision: [ "int8", "fp32" ]
        exclude:
          - backend: tf
          - backend: pytorch
          - backend: onnxruntime
          - precision: fp32

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        python3 -m pip install cmind
        # cm pull repo --url=${{ github.event.pull_request.head.repo.html_url }} --checkout=${{ github.event.pull_request.head.ref }}
        cm pull repo --url=${{ github.event.pull_request.head.repo.html_url }}
        cm run script --quiet --tags=get,sys-utils-cm
    - name: Test MLPerf Inference Bert (DeepSparse, TF, ONNX, PyTorch)
      run: |
        cm run script --tags=run,mlperf,inference,generate-run-cmds,_submission,_short --submitter="cTuning" --model=bert-99 --backend=${{ matrix.backend }} --device=cpu --scenario=Offline --test_query_count=5 --precision=${{ matrix.precision }} --target_qps=1 -v --quiet
